{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "65fa5c44",
      "metadata": {
        "id": "65fa5c44"
      },
      "source": [
        "# ADV ML HW1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c0515e2",
      "metadata": {
        "id": "7c0515e2"
      },
      "source": [
        "# Estelle Chan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ebc368",
      "metadata": {
        "id": "43ebc368"
      },
      "outputs": [],
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f761e43",
      "metadata": {
        "id": "6f761e43"
      },
      "outputs": [],
      "source": [
        "#Get competition data from course folder and unzip\n",
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "  \n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"world_happiness_competition_data.zip\", 'r') as zObject:\n",
        "  \n",
        "    # Extracting all the members of the zip \n",
        "    # into a specific location.\n",
        "    zObject.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1666e9d3",
      "metadata": {
        "id": "1666e9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "6c078dcf-a7ef-4b0a-e14e-caa026954bdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Country or region  GDP per capita  Social support  Healthy life expectancy  \\\n",
              "0              Peru           0.960           1.274                    0.854   \n",
              "1         Nicaragua           0.694           1.325                    0.835   \n",
              "2            Greece           1.181           1.156                    0.999   \n",
              "3             Qatar           1.684           1.313                    0.871   \n",
              "4        Uzbekistan           0.745           1.529                    0.756   \n",
              "\n",
              "   Freedom to make life choices  Generosity  Perceptions of corruption  \\\n",
              "0                         0.455       0.083                      0.027   \n",
              "1                         0.435       0.200                      0.127   \n",
              "2                         0.067       0.000                      0.034   \n",
              "3                         0.555       0.220                      0.167   \n",
              "4                         0.631       0.322                      0.240   \n",
              "\n",
              "         name    region                       sub-region  Terrorist_attacks  \n",
              "0        Peru  Americas  Latin America and the Caribbean          18.000000  \n",
              "1   Nicaragua  Americas  Latin America and the Caribbean         125.611111  \n",
              "2      Greece    Europe                  Southern Europe         112.000000  \n",
              "3       Qatar      Asia                     Western Asia          57.333333  \n",
              "4  Uzbekistan      Asia                     Central Asia         125.611111  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-deb33f4c-82ae-451b-9c35-ffdbd9e169ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country or region</th>\n",
              "      <th>GDP per capita</th>\n",
              "      <th>Social support</th>\n",
              "      <th>Healthy life expectancy</th>\n",
              "      <th>Freedom to make life choices</th>\n",
              "      <th>Generosity</th>\n",
              "      <th>Perceptions of corruption</th>\n",
              "      <th>name</th>\n",
              "      <th>region</th>\n",
              "      <th>sub-region</th>\n",
              "      <th>Terrorist_attacks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Peru</td>\n",
              "      <td>0.960</td>\n",
              "      <td>1.274</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.027</td>\n",
              "      <td>Peru</td>\n",
              "      <td>Americas</td>\n",
              "      <td>Latin America and the Caribbean</td>\n",
              "      <td>18.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nicaragua</td>\n",
              "      <td>0.694</td>\n",
              "      <td>1.325</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.435</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.127</td>\n",
              "      <td>Nicaragua</td>\n",
              "      <td>Americas</td>\n",
              "      <td>Latin America and the Caribbean</td>\n",
              "      <td>125.611111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Greece</td>\n",
              "      <td>1.181</td>\n",
              "      <td>1.156</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.067</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.034</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Europe</td>\n",
              "      <td>Southern Europe</td>\n",
              "      <td>112.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Qatar</td>\n",
              "      <td>1.684</td>\n",
              "      <td>1.313</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.167</td>\n",
              "      <td>Qatar</td>\n",
              "      <td>Asia</td>\n",
              "      <td>Western Asia</td>\n",
              "      <td>57.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Uzbekistan</td>\n",
              "      <td>0.745</td>\n",
              "      <td>1.529</td>\n",
              "      <td>0.756</td>\n",
              "      <td>0.631</td>\n",
              "      <td>0.322</td>\n",
              "      <td>0.240</td>\n",
              "      <td>Uzbekistan</td>\n",
              "      <td>Asia</td>\n",
              "      <td>Central Asia</td>\n",
              "      <td>125.611111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deb33f4c-82ae-451b-9c35-ffdbd9e169ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-deb33f4c-82ae-451b-9c35-ffdbd9e169ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-deb33f4c-82ae-451b-9c35-ffdbd9e169ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Load data\n",
        "import pandas as pd\n",
        "X_train = pd.read_csv('world_happiness_competition_data/X_train.csv')\n",
        "X_test = pd.read_csv('world_happiness_competition_data/X_test.csv')\n",
        "y_train = pd.read_csv('world_happiness_competition_data/y_train.csv')\n",
        "y_train_labels = y_train.idxmax(axis=1)\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d688ec",
      "metadata": {
        "id": "14d688ec"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "\n",
        "numeric_features = X_train.drop(['Country or region', 'name', 'region', 'sub-region'], axis=1)\n",
        "numeric_features=numeric_features.columns.tolist()\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['region', 'sub-region']\n",
        "\n",
        "#Replacing missing values with Modal value and then one hot encoding.\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# final preprocessor object set up with ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "#Fit your preprocessor object\n",
        "preprocess=preprocessor.fit(X_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68b5e7d",
      "metadata": {
        "id": "a68b5e7d"
      },
      "outputs": [],
      "source": [
        "# Write function to transform data with preprocessor\n",
        "\n",
        "def preprocessor(data):\n",
        "    data.drop(['Country or region', 'name'], axis=1)\n",
        "    preprocessed_data=preprocess.transform(data)\n",
        "    return preprocessed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a32147",
      "metadata": {
        "id": "f5a32147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b17751-d080-4e11-889f-8829bc0be416"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# check shape of X data after preprocessing it using our new function\n",
        "preprocessor(X_train).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a86697cb",
      "metadata": {
        "id": "a86697cb"
      },
      "source": [
        "## Q1.Explore bivariate results (Use visualizations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e4489e",
      "metadata": {
        "id": "76e4489e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "80a3e454-0065-496c-fa3c-025ae22787d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "plot1 = sns.regplot(x=\"Healthy life expectancy\", y= y_train.iloc[:,0], data=X_train, color='g')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4a7903",
      "metadata": {
        "id": "6b4a7903"
      },
      "source": [
        "From the first plot we can find out there are positive relationship between 'Health Life Expectancy' and 'Average Life Evaluation'. When the 'Health Life Expectancy'increases, 'Average Life Evaluation' will increase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dfc5331",
      "metadata": {
        "id": "3dfc5331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "8a2efe27-ce47-4c1f-d002-1133ce18b119"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot2= sns.regplot(x=\"Freedom to make life choices\", y= y_train.iloc[:,0], data=X_train, color='b')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the second plot, we can find out there are negative relationship between 'Freedom to make life choices' and 'Average Life Evaluation'. When'Freedom to make life choices' increase, 'Average Life Evaluation' will decrease."
      ],
      "metadata": {
        "id": "bfdTnbDae60Q"
      },
      "id": "bfdTnbDae60Q"
    },
    {
      "cell_type": "markdown",
      "id": "1235a9ef",
      "metadata": {
        "id": "1235a9ef"
      },
      "source": [
        "## Q2. Examine features that predict happiness categories using one or more models that allow for automatic feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1bcf62",
      "metadata": {
        "id": "7f1bcf62"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea118c6",
      "metadata": {
        "id": "fea118c6"
      },
      "outputs": [],
      "source": [
        "x = X_train.iloc[:,1:7]\n",
        "y = y_train.iloc[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ced478",
      "metadata": {
        "id": "d8ced478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49531cc-7eea-4a6b-e09c-ab8206ef2666"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=RandomForestClassifier())"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0fb32fe",
      "metadata": {
        "id": "f0fb32fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ed4baf-5055-4da4-8977-2ca2ac04f7b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "selected_feat= x.columns[(sel.get_support())]\n",
        "len(selected_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "975af796",
      "metadata": {
        "id": "975af796",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15563f1f-69a5-4eb1-eac4-31556d4e1e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['GDP per capita', 'Generosity', 'Perceptions of corruption'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(selected_feat)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use Random Forest Classifier to select features, 'GDP per capita', 'Generosity', and 'Perceptions of corruption' are automatically selected."
      ],
      "metadata": {
        "id": "SfC7zwU1H0T2"
      },
      "id": "SfC7zwU1H0T2"
    },
    {
      "cell_type": "markdown",
      "id": "91b2895a",
      "metadata": {
        "id": "91b2895a"
      },
      "source": [
        "## Q3.Experiment with different prediction models to try to predict World Happiness well (Fit and compare, at minimum, three models)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before discussion"
      ],
      "metadata": {
        "id": "8tBwiPc5GZEO"
      },
      "id": "8tBwiPc5GZEO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: Random Forest"
      ],
      "metadata": {
        "id": "Pwhmy7Bz5A9C"
      },
      "id": "Pwhmy7Bz5A9C"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "param_grid = {'n_estimators': np.arange(100, 300, 500),'max_depth':[1, 3, 5]} #np.arange creates sequence of numbers for each k value\n",
        "\n",
        "gridmodel = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=10)\n",
        "\n",
        "#use meta model methods to fit score and predict model:\n",
        "gridmodel.fit(preprocessor(X_train), y_train_labels)\n",
        "\n",
        "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(gridmodel.best_score_))\n",
        "print(\"best parameters: {}\".format(gridmodel.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toxlFkoQBGYh",
        "outputId": "967ce66e-a9b8-4e19-be36-3b32e83f4d9e"
      },
      "id": "toxlFkoQBGYh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best mean cross-validation score: 0.669\n",
            "best parameters: {'max_depth': 5, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
        "model_1.fit(preprocessor(X_train), y_train_labels) # Fitting to the training set.\n",
        "model_1.score(preprocessor(X_train), y_train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fTOhmoZIlxA",
        "outputId": "48e00f68-230a-4321-e843-9bd4e1d65944"
      },
      "id": "-fTOhmoZIlxA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9545454545454546"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5rafyBAIzPf",
        "outputId": "78040345-ef22-402f-e65b-87aa25a21f50"
      },
      "id": "T5rafyBAIzPf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "# Check how many preprocessed input features are there?\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "feature_count=preprocessor(X_test).shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  #Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model = model_to_onnx(model_1, framework='sklearn',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=False)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "72AzjCNcI0bR"
      },
      "id": "72AzjCNcI0bR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "\n",
        "#This is the unique rest api that powers this World Happiness Classification Playground -- make sure to update the apiurl for new competition deployments\n",
        "apiurl=\"https://e2w6gh3id1.execute-api.us-east-2.amazonaws.com/prod/m\"\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjgtv8nwI6Lz",
        "outputId": "106736cf-f2c5-470a-dc04-17ce5118b3f1"
      },
      "id": "Yjgtv8nwI6Lz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:\n",
            "AI Modelshare Password:\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate Competition\n",
        "import aimodelshare as ai\n",
        "mycompetition= ai.Competition(apiurl)"
      ],
      "metadata": {
        "id": "hNsaT46qI-VE"
      },
      "id": "hNsaT46qI-VE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 1: \n",
        "\n",
        "#-- Generate predicted values (Model 1)\n",
        "prediction_labels = model_1.predict(preprocessor(X_test))\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels, custom_metadata={\"team\":\"1\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YL9Rr4TJC3F",
        "outputId": "96d68907-bfce-4a13-9af7-56da865c3537"
      },
      "id": "6YL9Rr4TJC3F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 817\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "Xck_1shsJNRq"
      },
      "id": "Xck_1shsJNRq"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "param_grid_2 = {'n_estimators': np.arange(100, 300, 500),'max_depth':[1, 3, 5]} #np.arange creates sequence of numbers for each k value\n",
        "\n",
        "gridmodel_2 = GridSearchCV(GradientBoostingClassifier(), param_grid=param_grid, cv=10)\n",
        "\n",
        "#use meta model methods to fit score and predict model:\n",
        "gridmodel_2.fit(preprocessor(X_train), y_train_labels)\n",
        "\n",
        "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(gridmodel_2.best_score_))\n",
        "print(\"best parameters: {}\".format(gridmodel_2.best_params_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F44tlDlxJWDC",
        "outputId": "88edf81e-ca90-4cd6-b522-5327d1f97595"
      },
      "id": "F44tlDlxJWDC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best mean cross-validation score: 0.626\n",
            "best parameters: {'max_depth': 1, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
        "    max_depth=1, random_state=0).fit(preprocessor(X_train), y_train_labels)\n",
        "model_2.score(preprocessor(X_train), y_train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aDUG6WOK5Q8",
        "outputId": "32bae689-4b25-45f8-ba8a-d63ec9741437"
      },
      "id": "0aDUG6WOK5Q8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "feature_count=preprocessor(X_test).shape[1] #Get count of preprocessed features\n",
        "initial_type = [('float_input', FloatTensorType([None, feature_count]))]  # Insert correct number of preprocessed features\n",
        "\n",
        "onnx_model = model_to_onnx(model_2, framework='sklearn',\n",
        "                          initial_types=initial_type,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=False)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "iR1Dx2ypK_uu"
      },
      "id": "iR1Dx2ypK_uu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Generate predicted values \n",
        "prediction_labels = model_2.predict(preprocessor(X_test))"
      ],
      "metadata": {
        "id": "11Bsi7F3LPHX"
      },
      "id": "11Bsi7F3LPHX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit model to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels, custom_metadata={\"team\":\"1\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWQuOVpyLQGB",
        "outputId": "888da28b-4fc1-471a-9212-cc9a49b8b40e"
      },
      "id": "QWQuOVpyLQGB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 818\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Deep Learning"
      ],
      "metadata": {
        "id": "4px4rdu-Lgtb"
      },
      "id": "4px4rdu-Lgtb"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "feature_count=preprocessor(X_train).shape[1] #count features in input data\n",
        "\n",
        "keras_model = Sequential()\n",
        "keras_model.add(Dense(128, input_dim=feature_count, activation='relu'))\n",
        "keras_model.add(Dense(64, activation='relu'))\n",
        "keras_model.add(Dense(64, activation='relu'))\n",
        "keras_model.add(Dense(32, activation='relu'))\n",
        "\n",
        "keras_model.add(Dense(5, activation='softmax')) \n",
        "                                            \n",
        "# Compile model\n",
        "keras_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# Fitting the NN to the Training set\n",
        "keras_model.fit(preprocessor(X_train), y_train, ## Note that keras models require a one-hot-encoded y_train object\n",
        "               batch_size = 20, \n",
        "               epochs = 300, validation_split=0.25)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2j57rcaQdLS",
        "outputId": "e4543706-c0bc-4f97-f2f6-a670e859b3d0"
      },
      "id": "E2j57rcaQdLS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 74ms/step - loss: 1.5801 - accuracy: 0.2879 - val_loss: 1.5905 - val_accuracy: 0.2273\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.5671 - accuracy: 0.3333 - val_loss: 1.5835 - val_accuracy: 0.2273\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.5561 - accuracy: 0.3333 - val_loss: 1.5753 - val_accuracy: 0.2273\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.5428 - accuracy: 0.3485 - val_loss: 1.5682 - val_accuracy: 0.2273\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.5323 - accuracy: 0.3636 - val_loss: 1.5610 - val_accuracy: 0.2727\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5199 - accuracy: 0.3939 - val_loss: 1.5556 - val_accuracy: 0.2273\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5074 - accuracy: 0.4697 - val_loss: 1.5491 - val_accuracy: 0.2727\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4957 - accuracy: 0.4697 - val_loss: 1.5400 - val_accuracy: 0.2727\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4816 - accuracy: 0.4848 - val_loss: 1.5324 - val_accuracy: 0.2727\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4706 - accuracy: 0.4848 - val_loss: 1.5264 - val_accuracy: 0.2727\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4591 - accuracy: 0.4848 - val_loss: 1.5175 - val_accuracy: 0.2727\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4462 - accuracy: 0.4848 - val_loss: 1.5102 - val_accuracy: 0.3182\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4350 - accuracy: 0.5152 - val_loss: 1.5023 - val_accuracy: 0.3182\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4236 - accuracy: 0.5455 - val_loss: 1.4926 - val_accuracy: 0.3182\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.4096 - accuracy: 0.5606 - val_loss: 1.4828 - val_accuracy: 0.3636\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3959 - accuracy: 0.5606 - val_loss: 1.4730 - val_accuracy: 0.3636\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3833 - accuracy: 0.5909 - val_loss: 1.4647 - val_accuracy: 0.3636\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3720 - accuracy: 0.5909 - val_loss: 1.4547 - val_accuracy: 0.3636\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3577 - accuracy: 0.5758 - val_loss: 1.4442 - val_accuracy: 0.4091\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3438 - accuracy: 0.6061 - val_loss: 1.4344 - val_accuracy: 0.4091\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3303 - accuracy: 0.6061 - val_loss: 1.4266 - val_accuracy: 0.4091\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3182 - accuracy: 0.6061 - val_loss: 1.4163 - val_accuracy: 0.4091\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.3055 - accuracy: 0.6364 - val_loss: 1.4055 - val_accuracy: 0.4091\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.2912 - accuracy: 0.6212 - val_loss: 1.3951 - val_accuracy: 0.4091\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2778 - accuracy: 0.6667 - val_loss: 1.3876 - val_accuracy: 0.4091\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2643 - accuracy: 0.6667 - val_loss: 1.3765 - val_accuracy: 0.4545\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.2511 - accuracy: 0.6667 - val_loss: 1.3672 - val_accuracy: 0.4091\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2364 - accuracy: 0.6667 - val_loss: 1.3554 - val_accuracy: 0.4545\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2228 - accuracy: 0.6667 - val_loss: 1.3474 - val_accuracy: 0.4545\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.2105 - accuracy: 0.6667 - val_loss: 1.3385 - val_accuracy: 0.4545\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1974 - accuracy: 0.6667 - val_loss: 1.3307 - val_accuracy: 0.4545\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.1857 - accuracy: 0.6667 - val_loss: 1.3236 - val_accuracy: 0.4545\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1753 - accuracy: 0.6667 - val_loss: 1.3118 - val_accuracy: 0.4545\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1617 - accuracy: 0.6970 - val_loss: 1.3036 - val_accuracy: 0.4545\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1496 - accuracy: 0.6818 - val_loss: 1.2969 - val_accuracy: 0.4545\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1376 - accuracy: 0.6818 - val_loss: 1.2892 - val_accuracy: 0.4545\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1275 - accuracy: 0.6818 - val_loss: 1.2811 - val_accuracy: 0.4545\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1165 - accuracy: 0.6818 - val_loss: 1.2712 - val_accuracy: 0.4545\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1053 - accuracy: 0.6970 - val_loss: 1.2637 - val_accuracy: 0.4091\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0954 - accuracy: 0.6970 - val_loss: 1.2539 - val_accuracy: 0.4091\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.0846 - accuracy: 0.6970 - val_loss: 1.2453 - val_accuracy: 0.4091\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.0741 - accuracy: 0.6970 - val_loss: 1.2405 - val_accuracy: 0.4091\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0640 - accuracy: 0.6970 - val_loss: 1.2375 - val_accuracy: 0.4545\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0523 - accuracy: 0.6818 - val_loss: 1.2342 - val_accuracy: 0.4545\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0430 - accuracy: 0.6818 - val_loss: 1.2276 - val_accuracy: 0.4545\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0332 - accuracy: 0.6818 - val_loss: 1.2231 - val_accuracy: 0.4545\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0230 - accuracy: 0.6818 - val_loss: 1.2190 - val_accuracy: 0.4545\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0140 - accuracy: 0.6818 - val_loss: 1.2103 - val_accuracy: 0.4545\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0058 - accuracy: 0.6818 - val_loss: 1.2076 - val_accuracy: 0.4545\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.9961 - accuracy: 0.6818 - val_loss: 1.2001 - val_accuracy: 0.4545\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.9875 - accuracy: 0.6818 - val_loss: 1.1949 - val_accuracy: 0.4545\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.9779 - accuracy: 0.6818 - val_loss: 1.1856 - val_accuracy: 0.4545\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.9712 - accuracy: 0.6818 - val_loss: 1.1788 - val_accuracy: 0.4545\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.9622 - accuracy: 0.6818 - val_loss: 1.1750 - val_accuracy: 0.4545\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.9532 - accuracy: 0.6818 - val_loss: 1.1672 - val_accuracy: 0.4545\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.9448 - accuracy: 0.6818 - val_loss: 1.1630 - val_accuracy: 0.4545\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.9370 - accuracy: 0.6818 - val_loss: 1.1552 - val_accuracy: 0.4545\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.9304 - accuracy: 0.6970 - val_loss: 1.1478 - val_accuracy: 0.4545\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9216 - accuracy: 0.6970 - val_loss: 1.1427 - val_accuracy: 0.4545\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.9142 - accuracy: 0.7121 - val_loss: 1.1377 - val_accuracy: 0.5000\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.9071 - accuracy: 0.6970 - val_loss: 1.1332 - val_accuracy: 0.5000\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.9003 - accuracy: 0.6970 - val_loss: 1.1253 - val_accuracy: 0.5455\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.8925 - accuracy: 0.6970 - val_loss: 1.1243 - val_accuracy: 0.5000\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.8835 - accuracy: 0.7424 - val_loss: 1.1158 - val_accuracy: 0.5000\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.8772 - accuracy: 0.7424 - val_loss: 1.1077 - val_accuracy: 0.5455\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.8701 - accuracy: 0.7273 - val_loss: 1.1073 - val_accuracy: 0.5000\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.8621 - accuracy: 0.7576 - val_loss: 1.1047 - val_accuracy: 0.5000\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.8559 - accuracy: 0.7576 - val_loss: 1.1006 - val_accuracy: 0.5455\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.8491 - accuracy: 0.7879 - val_loss: 1.0924 - val_accuracy: 0.5455\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.8428 - accuracy: 0.7576 - val_loss: 1.0860 - val_accuracy: 0.5455\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.8342 - accuracy: 0.7576 - val_loss: 1.0775 - val_accuracy: 0.5909\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.8291 - accuracy: 0.7727 - val_loss: 1.0717 - val_accuracy: 0.5455\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.8228 - accuracy: 0.7727 - val_loss: 1.0674 - val_accuracy: 0.5455\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.8163 - accuracy: 0.7576 - val_loss: 1.0625 - val_accuracy: 0.5455\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.8095 - accuracy: 0.7576 - val_loss: 1.0614 - val_accuracy: 0.5909\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.8034 - accuracy: 0.7576 - val_loss: 1.0576 - val_accuracy: 0.5909\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.7987 - accuracy: 0.7576 - val_loss: 1.0540 - val_accuracy: 0.5909\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.7919 - accuracy: 0.7727 - val_loss: 1.0604 - val_accuracy: 0.5455\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.7859 - accuracy: 0.8030 - val_loss: 1.0559 - val_accuracy: 0.5455\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.7796 - accuracy: 0.7879 - val_loss: 1.0508 - val_accuracy: 0.6364\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.7728 - accuracy: 0.8030 - val_loss: 1.0447 - val_accuracy: 0.5909\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.7696 - accuracy: 0.8030 - val_loss: 1.0405 - val_accuracy: 0.5909\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7633 - accuracy: 0.8030 - val_loss: 1.0386 - val_accuracy: 0.5909\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.7578 - accuracy: 0.8030 - val_loss: 1.0383 - val_accuracy: 0.5909\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7518 - accuracy: 0.8030 - val_loss: 1.0368 - val_accuracy: 0.5909\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7465 - accuracy: 0.8030 - val_loss: 1.0269 - val_accuracy: 0.6364\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7422 - accuracy: 0.8030 - val_loss: 1.0232 - val_accuracy: 0.6364\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7369 - accuracy: 0.8030 - val_loss: 1.0252 - val_accuracy: 0.6364\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7307 - accuracy: 0.8030 - val_loss: 1.0349 - val_accuracy: 0.5455\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7274 - accuracy: 0.7727 - val_loss: 1.0348 - val_accuracy: 0.5000\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7208 - accuracy: 0.7879 - val_loss: 1.0274 - val_accuracy: 0.5000\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7149 - accuracy: 0.7879 - val_loss: 1.0233 - val_accuracy: 0.5000\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.7102 - accuracy: 0.7879 - val_loss: 1.0221 - val_accuracy: 0.5000\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7046 - accuracy: 0.7879 - val_loss: 1.0148 - val_accuracy: 0.5909\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6995 - accuracy: 0.8030 - val_loss: 1.0162 - val_accuracy: 0.5455\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.7879 - val_loss: 1.0152 - val_accuracy: 0.5455\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6885 - accuracy: 0.7879 - val_loss: 1.0098 - val_accuracy: 0.5455\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6837 - accuracy: 0.7879 - val_loss: 1.0135 - val_accuracy: 0.5455\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6810 - accuracy: 0.7879 - val_loss: 1.0136 - val_accuracy: 0.5455\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6751 - accuracy: 0.7879 - val_loss: 0.9995 - val_accuracy: 0.5909\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6721 - accuracy: 0.8030 - val_loss: 1.0021 - val_accuracy: 0.5909\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6662 - accuracy: 0.7879 - val_loss: 0.9965 - val_accuracy: 0.5909\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6609 - accuracy: 0.8182 - val_loss: 0.9942 - val_accuracy: 0.5909\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6571 - accuracy: 0.8182 - val_loss: 0.9961 - val_accuracy: 0.5909\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6531 - accuracy: 0.8182 - val_loss: 0.9946 - val_accuracy: 0.5909\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6475 - accuracy: 0.8182 - val_loss: 0.9901 - val_accuracy: 0.5909\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6442 - accuracy: 0.8182 - val_loss: 0.9825 - val_accuracy: 0.5909\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6406 - accuracy: 0.8182 - val_loss: 0.9902 - val_accuracy: 0.5909\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6352 - accuracy: 0.8182 - val_loss: 0.9945 - val_accuracy: 0.5909\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.6329 - accuracy: 0.7879 - val_loss: 0.9947 - val_accuracy: 0.5909\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6281 - accuracy: 0.8030 - val_loss: 0.9886 - val_accuracy: 0.5909\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6239 - accuracy: 0.7879 - val_loss: 0.9897 - val_accuracy: 0.5909\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6260 - accuracy: 0.8030 - val_loss: 0.9891 - val_accuracy: 0.6364\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6184 - accuracy: 0.8333 - val_loss: 0.9890 - val_accuracy: 0.6364\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.6125 - accuracy: 0.8182 - val_loss: 0.9821 - val_accuracy: 0.6364\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6104 - accuracy: 0.8182 - val_loss: 0.9894 - val_accuracy: 0.5455\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6049 - accuracy: 0.8333 - val_loss: 0.9992 - val_accuracy: 0.5455\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.6031 - accuracy: 0.8182 - val_loss: 0.9931 - val_accuracy: 0.5455\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5992 - accuracy: 0.8182 - val_loss: 0.9969 - val_accuracy: 0.5455\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5932 - accuracy: 0.8182 - val_loss: 0.9888 - val_accuracy: 0.5455\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5902 - accuracy: 0.8333 - val_loss: 0.9831 - val_accuracy: 0.5455\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5842 - accuracy: 0.8333 - val_loss: 0.9829 - val_accuracy: 0.5455\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5805 - accuracy: 0.8182 - val_loss: 0.9697 - val_accuracy: 0.6364\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.5779 - accuracy: 0.8485 - val_loss: 0.9664 - val_accuracy: 0.5909\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5751 - accuracy: 0.8485 - val_loss: 0.9619 - val_accuracy: 0.6364\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5708 - accuracy: 0.8333 - val_loss: 0.9594 - val_accuracy: 0.6364\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5678 - accuracy: 0.8333 - val_loss: 0.9606 - val_accuracy: 0.6364\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5626 - accuracy: 0.8333 - val_loss: 0.9608 - val_accuracy: 0.6364\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5638 - accuracy: 0.8333 - val_loss: 0.9632 - val_accuracy: 0.6364\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5583 - accuracy: 0.8485 - val_loss: 0.9670 - val_accuracy: 0.6364\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5530 - accuracy: 0.8333 - val_loss: 0.9721 - val_accuracy: 0.6364\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5499 - accuracy: 0.8333 - val_loss: 0.9814 - val_accuracy: 0.5909\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5454 - accuracy: 0.8333 - val_loss: 0.9695 - val_accuracy: 0.6364\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5426 - accuracy: 0.8485 - val_loss: 0.9653 - val_accuracy: 0.6364\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5398 - accuracy: 0.8333 - val_loss: 0.9708 - val_accuracy: 0.5909\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5344 - accuracy: 0.8333 - val_loss: 0.9716 - val_accuracy: 0.5909\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5361 - accuracy: 0.8333 - val_loss: 0.9643 - val_accuracy: 0.6364\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5298 - accuracy: 0.8333 - val_loss: 0.9648 - val_accuracy: 0.6364\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5283 - accuracy: 0.8333 - val_loss: 0.9660 - val_accuracy: 0.6364\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5238 - accuracy: 0.8485 - val_loss: 0.9656 - val_accuracy: 0.6364\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5243 - accuracy: 0.8485 - val_loss: 0.9739 - val_accuracy: 0.5909\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5157 - accuracy: 0.8485 - val_loss: 0.9717 - val_accuracy: 0.6364\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.5144 - accuracy: 0.8485 - val_loss: 0.9778 - val_accuracy: 0.6364\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5111 - accuracy: 0.8485 - val_loss: 0.9835 - val_accuracy: 0.6364\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5054 - accuracy: 0.8485 - val_loss: 0.9729 - val_accuracy: 0.6364\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5024 - accuracy: 0.8333 - val_loss: 0.9771 - val_accuracy: 0.5909\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4967 - accuracy: 0.8333 - val_loss: 0.9820 - val_accuracy: 0.5909\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4944 - accuracy: 0.8636 - val_loss: 0.9853 - val_accuracy: 0.6364\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4920 - accuracy: 0.8485 - val_loss: 0.9837 - val_accuracy: 0.6364\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4879 - accuracy: 0.8485 - val_loss: 0.9844 - val_accuracy: 0.6364\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4855 - accuracy: 0.8485 - val_loss: 0.9894 - val_accuracy: 0.6364\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4843 - accuracy: 0.8636 - val_loss: 1.0034 - val_accuracy: 0.5909\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4839 - accuracy: 0.8485 - val_loss: 0.9921 - val_accuracy: 0.5909\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4782 - accuracy: 0.8939 - val_loss: 0.9831 - val_accuracy: 0.5909\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4747 - accuracy: 0.8485 - val_loss: 0.9947 - val_accuracy: 0.5909\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4703 - accuracy: 0.8485 - val_loss: 0.9976 - val_accuracy: 0.5909\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4667 - accuracy: 0.8788 - val_loss: 0.9891 - val_accuracy: 0.6364\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4648 - accuracy: 0.8485 - val_loss: 0.9838 - val_accuracy: 0.5455\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4599 - accuracy: 0.8788 - val_loss: 0.9890 - val_accuracy: 0.5909\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4576 - accuracy: 0.8788 - val_loss: 0.9937 - val_accuracy: 0.6364\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4557 - accuracy: 0.8636 - val_loss: 0.9992 - val_accuracy: 0.6364\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4527 - accuracy: 0.8788 - val_loss: 1.0086 - val_accuracy: 0.5909\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4509 - accuracy: 0.8636 - val_loss: 1.0165 - val_accuracy: 0.5455\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4487 - accuracy: 0.8485 - val_loss: 1.0302 - val_accuracy: 0.5909\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4435 - accuracy: 0.8485 - val_loss: 1.0129 - val_accuracy: 0.6364\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4459 - accuracy: 0.8636 - val_loss: 1.0077 - val_accuracy: 0.6364\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4390 - accuracy: 0.8788 - val_loss: 1.0014 - val_accuracy: 0.5909\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4374 - accuracy: 0.8939 - val_loss: 1.0033 - val_accuracy: 0.5909\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4333 - accuracy: 0.8788 - val_loss: 1.0004 - val_accuracy: 0.5455\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4295 - accuracy: 0.8636 - val_loss: 0.9979 - val_accuracy: 0.5909\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4271 - accuracy: 0.8636 - val_loss: 0.9897 - val_accuracy: 0.5909\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4246 - accuracy: 0.8636 - val_loss: 0.9798 - val_accuracy: 0.6364\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4242 - accuracy: 0.8485 - val_loss: 0.9927 - val_accuracy: 0.5909\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4207 - accuracy: 0.8636 - val_loss: 1.0117 - val_accuracy: 0.5909\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4189 - accuracy: 0.9091 - val_loss: 1.0167 - val_accuracy: 0.5909\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4111 - accuracy: 0.8939 - val_loss: 1.0324 - val_accuracy: 0.5455\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4106 - accuracy: 0.9091 - val_loss: 1.0273 - val_accuracy: 0.5455\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4073 - accuracy: 0.8636 - val_loss: 1.0097 - val_accuracy: 0.5909\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4047 - accuracy: 0.8636 - val_loss: 1.0015 - val_accuracy: 0.5909\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4022 - accuracy: 0.9242 - val_loss: 0.9958 - val_accuracy: 0.5909\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3978 - accuracy: 0.8788 - val_loss: 0.9954 - val_accuracy: 0.5909\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3974 - accuracy: 0.8788 - val_loss: 0.9929 - val_accuracy: 0.6364\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3932 - accuracy: 0.8788 - val_loss: 1.0106 - val_accuracy: 0.5909\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.8636 - val_loss: 1.0116 - val_accuracy: 0.5909\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3870 - accuracy: 0.8939 - val_loss: 1.0184 - val_accuracy: 0.5909\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3818 - accuracy: 0.9091 - val_loss: 1.0139 - val_accuracy: 0.5909\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3798 - accuracy: 0.8939 - val_loss: 1.0202 - val_accuracy: 0.5909\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3767 - accuracy: 0.8788 - val_loss: 1.0096 - val_accuracy: 0.5909\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3772 - accuracy: 0.8788 - val_loss: 1.0315 - val_accuracy: 0.6364\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3766 - accuracy: 0.9242 - val_loss: 1.0248 - val_accuracy: 0.5909\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3713 - accuracy: 0.9242 - val_loss: 1.0493 - val_accuracy: 0.5455\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3725 - accuracy: 0.9242 - val_loss: 1.0381 - val_accuracy: 0.5909\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3685 - accuracy: 0.8788 - val_loss: 1.0353 - val_accuracy: 0.5909\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3645 - accuracy: 0.9242 - val_loss: 1.0443 - val_accuracy: 0.5909\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3625 - accuracy: 0.9242 - val_loss: 1.0372 - val_accuracy: 0.5909\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3601 - accuracy: 0.9242 - val_loss: 1.0495 - val_accuracy: 0.5909\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3593 - accuracy: 0.9242 - val_loss: 1.0435 - val_accuracy: 0.5909\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3542 - accuracy: 0.9242 - val_loss: 1.0487 - val_accuracy: 0.5909\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3537 - accuracy: 0.8788 - val_loss: 1.0376 - val_accuracy: 0.5909\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3471 - accuracy: 0.9242 - val_loss: 1.0485 - val_accuracy: 0.5909\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3462 - accuracy: 0.9091 - val_loss: 1.0499 - val_accuracy: 0.5909\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3443 - accuracy: 0.9091 - val_loss: 1.0473 - val_accuracy: 0.5909\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3401 - accuracy: 0.8939 - val_loss: 1.0517 - val_accuracy: 0.5909\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3375 - accuracy: 0.9242 - val_loss: 1.0600 - val_accuracy: 0.5909\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3342 - accuracy: 0.9394 - val_loss: 1.0345 - val_accuracy: 0.5909\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3351 - accuracy: 0.9091 - val_loss: 1.0541 - val_accuracy: 0.5909\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3285 - accuracy: 0.9242 - val_loss: 1.0346 - val_accuracy: 0.6364\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3299 - accuracy: 0.8939 - val_loss: 1.0375 - val_accuracy: 0.5909\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3262 - accuracy: 0.8788 - val_loss: 1.0586 - val_accuracy: 0.5909\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3212 - accuracy: 0.8939 - val_loss: 1.0559 - val_accuracy: 0.5909\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3226 - accuracy: 0.9242 - val_loss: 1.0645 - val_accuracy: 0.5909\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3200 - accuracy: 0.9242 - val_loss: 1.0402 - val_accuracy: 0.6364\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3212 - accuracy: 0.9242 - val_loss: 1.0579 - val_accuracy: 0.6364\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3149 - accuracy: 0.9242 - val_loss: 1.0743 - val_accuracy: 0.5909\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3169 - accuracy: 0.9242 - val_loss: 1.0798 - val_accuracy: 0.5909\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3083 - accuracy: 0.9242 - val_loss: 1.0759 - val_accuracy: 0.5909\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3067 - accuracy: 0.9394 - val_loss: 1.0825 - val_accuracy: 0.5909\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3054 - accuracy: 0.9242 - val_loss: 1.0890 - val_accuracy: 0.5909\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3044 - accuracy: 0.9242 - val_loss: 1.0863 - val_accuracy: 0.5909\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2994 - accuracy: 0.9242 - val_loss: 1.0927 - val_accuracy: 0.5909\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2981 - accuracy: 0.9091 - val_loss: 1.0836 - val_accuracy: 0.5909\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3002 - accuracy: 0.9091 - val_loss: 1.0821 - val_accuracy: 0.5909\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2958 - accuracy: 0.9091 - val_loss: 1.1026 - val_accuracy: 0.5909\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2924 - accuracy: 0.9091 - val_loss: 1.1033 - val_accuracy: 0.5909\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2921 - accuracy: 0.9091 - val_loss: 1.1117 - val_accuracy: 0.5909\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2911 - accuracy: 0.9242 - val_loss: 1.0980 - val_accuracy: 0.5909\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2886 - accuracy: 0.9242 - val_loss: 1.1029 - val_accuracy: 0.5909\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2822 - accuracy: 0.9242 - val_loss: 1.1143 - val_accuracy: 0.5909\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2826 - accuracy: 0.9394 - val_loss: 1.1057 - val_accuracy: 0.5909\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2799 - accuracy: 0.9242 - val_loss: 1.1099 - val_accuracy: 0.5909\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2807 - accuracy: 0.9394 - val_loss: 1.1009 - val_accuracy: 0.5909\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2749 - accuracy: 0.9242 - val_loss: 1.1084 - val_accuracy: 0.5909\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2768 - accuracy: 0.9394 - val_loss: 1.1240 - val_accuracy: 0.5909\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2720 - accuracy: 0.9394 - val_loss: 1.1437 - val_accuracy: 0.5909\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2706 - accuracy: 0.9242 - val_loss: 1.1356 - val_accuracy: 0.5909\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2676 - accuracy: 0.9394 - val_loss: 1.1476 - val_accuracy: 0.5909\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2696 - accuracy: 0.9394 - val_loss: 1.1129 - val_accuracy: 0.6364\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2649 - accuracy: 0.9394 - val_loss: 1.1391 - val_accuracy: 0.5909\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2633 - accuracy: 0.9545 - val_loss: 1.1487 - val_accuracy: 0.6364\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2622 - accuracy: 0.9242 - val_loss: 1.1795 - val_accuracy: 0.5909\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2624 - accuracy: 0.9545 - val_loss: 1.1587 - val_accuracy: 0.5909\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2598 - accuracy: 0.9545 - val_loss: 1.1507 - val_accuracy: 0.5909\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2577 - accuracy: 0.9697 - val_loss: 1.1361 - val_accuracy: 0.5909\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2554 - accuracy: 0.9545 - val_loss: 1.1299 - val_accuracy: 0.6364\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2529 - accuracy: 0.9545 - val_loss: 1.1284 - val_accuracy: 0.5909\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2491 - accuracy: 0.9697 - val_loss: 1.1369 - val_accuracy: 0.5909\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2485 - accuracy: 0.9697 - val_loss: 1.1476 - val_accuracy: 0.5909\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2456 - accuracy: 0.9697 - val_loss: 1.1475 - val_accuracy: 0.5909\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2447 - accuracy: 0.9545 - val_loss: 1.1560 - val_accuracy: 0.5909\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2425 - accuracy: 0.9697 - val_loss: 1.1581 - val_accuracy: 0.5909\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2379 - accuracy: 0.9697 - val_loss: 1.1663 - val_accuracy: 0.5909\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2381 - accuracy: 0.9697 - val_loss: 1.1656 - val_accuracy: 0.5909\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2364 - accuracy: 0.9697 - val_loss: 1.1794 - val_accuracy: 0.5909\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2356 - accuracy: 0.9697 - val_loss: 1.1532 - val_accuracy: 0.6364\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2374 - accuracy: 0.9545 - val_loss: 1.1349 - val_accuracy: 0.6364\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2349 - accuracy: 0.9394 - val_loss: 1.1625 - val_accuracy: 0.6364\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2360 - accuracy: 0.9545 - val_loss: 1.1592 - val_accuracy: 0.6364\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2276 - accuracy: 0.9697 - val_loss: 1.1782 - val_accuracy: 0.5909\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2280 - accuracy: 0.9697 - val_loss: 1.1806 - val_accuracy: 0.6364\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2254 - accuracy: 0.9545 - val_loss: 1.1756 - val_accuracy: 0.6364\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2242 - accuracy: 0.9545 - val_loss: 1.2202 - val_accuracy: 0.5909\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2284 - accuracy: 0.9697 - val_loss: 1.2135 - val_accuracy: 0.5909\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2208 - accuracy: 0.9697 - val_loss: 1.2088 - val_accuracy: 0.5909\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2185 - accuracy: 0.9697 - val_loss: 1.1916 - val_accuracy: 0.5909\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2192 - accuracy: 0.9697 - val_loss: 1.1586 - val_accuracy: 0.6364\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2175 - accuracy: 0.9394 - val_loss: 1.1648 - val_accuracy: 0.6364\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2167 - accuracy: 0.9697 - val_loss: 1.1716 - val_accuracy: 0.6364\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2121 - accuracy: 0.9697 - val_loss: 1.1993 - val_accuracy: 0.5909\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2139 - accuracy: 0.9545 - val_loss: 1.2142 - val_accuracy: 0.5909\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2152 - accuracy: 0.9545 - val_loss: 1.2199 - val_accuracy: 0.5909\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2088 - accuracy: 0.9697 - val_loss: 1.2281 - val_accuracy: 0.5909\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2094 - accuracy: 0.9697 - val_loss: 1.1798 - val_accuracy: 0.6364\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2066 - accuracy: 0.9545 - val_loss: 1.1968 - val_accuracy: 0.6364\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2056 - accuracy: 0.9697 - val_loss: 1.2056 - val_accuracy: 0.5909\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2050 - accuracy: 0.9697 - val_loss: 1.2186 - val_accuracy: 0.5909\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2078 - accuracy: 0.9697 - val_loss: 1.2237 - val_accuracy: 0.5909\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1987 - accuracy: 0.9697 - val_loss: 1.2316 - val_accuracy: 0.5909\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1987 - accuracy: 0.9697 - val_loss: 1.1891 - val_accuracy: 0.6364\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1998 - accuracy: 0.9545 - val_loss: 1.2026 - val_accuracy: 0.6364\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1984 - accuracy: 0.9697 - val_loss: 1.2287 - val_accuracy: 0.5909\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1972 - accuracy: 0.9697 - val_loss: 1.1923 - val_accuracy: 0.6364\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1985 - accuracy: 0.9545 - val_loss: 1.2055 - val_accuracy: 0.6818\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1969 - accuracy: 0.9545 - val_loss: 1.2100 - val_accuracy: 0.6364\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1882 - accuracy: 0.9545 - val_loss: 1.2262 - val_accuracy: 0.5909\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1892 - accuracy: 0.9697 - val_loss: 1.2571 - val_accuracy: 0.5909\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1903 - accuracy: 0.9697 - val_loss: 1.2487 - val_accuracy: 0.5909\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1878 - accuracy: 0.9697 - val_loss: 1.2519 - val_accuracy: 0.5909\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1820 - accuracy: 0.9697 - val_loss: 1.2586 - val_accuracy: 0.5909\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1842 - accuracy: 0.9697 - val_loss: 1.2792 - val_accuracy: 0.5909\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1858 - accuracy: 0.9697 - val_loss: 1.2795 - val_accuracy: 0.5909\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1828 - accuracy: 0.9697 - val_loss: 1.2335 - val_accuracy: 0.6364\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1820 - accuracy: 0.9545 - val_loss: 1.2564 - val_accuracy: 0.5909\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1805 - accuracy: 0.9545 - val_loss: 1.2903 - val_accuracy: 0.5909\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1802 - accuracy: 0.9697 - val_loss: 1.2984 - val_accuracy: 0.5909\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1743 - accuracy: 0.9697 - val_loss: 1.3006 - val_accuracy: 0.5909\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1760 - accuracy: 0.9697 - val_loss: 1.3010 - val_accuracy: 0.5909\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1752 - accuracy: 0.9697 - val_loss: 1.2974 - val_accuracy: 0.5909\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1732 - accuracy: 0.9697 - val_loss: 1.3052 - val_accuracy: 0.5909\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1725 - accuracy: 0.9697 - val_loss: 1.3081 - val_accuracy: 0.5909\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1723 - accuracy: 0.9697 - val_loss: 1.2546 - val_accuracy: 0.6364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e15c5f8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to ONNX file \n",
        "\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(keras_model, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "HCPW0ErZRKSj"
      },
      "id": "HCPW0ErZRKSj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit keras model: \n",
        "\n",
        "#-- Generate predicted y values\n",
        "#Note: Keras predict returns the predicted column index location for classification models\n",
        "prediction_column_index=keras_model.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels, custom_metadata={\"team\":\"1\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_D3r-r9RZHw",
        "outputId": "c396dbc6-6809-45b4-8a42-b7cf3c3eba06"
      },
      "id": "U_D3r-r9RZHw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 819\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After Discussion"
      ],
      "metadata": {
        "id": "xTmk5e3pRvtE"
      },
      "id": "xTmk5e3pRvtE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4"
      ],
      "metadata": {
        "id": "qgkn5DGQUEO8"
      },
      "id": "qgkn5DGQUEO8"
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = RandomForestClassifier(n_estimators=200, max_depth=5)\n",
        "model_4.fit(preprocessor(X_train), y_train_labels) # Fitting to the training set.\n",
        "model_4.score(preprocessor(X_train), y_train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHmdvtkLUH3F",
        "outputId": "7a105404-6b2f-42d2-e6e0-46f9a8c78696"
      },
      "id": "kHmdvtkLUH3F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9545454545454546"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Generate predicted values (Model 4)\n",
        "prediction_labels = model_4.predict(preprocessor(X_test))\n",
        "\n",
        "# Submit Model 4 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels,custom_metadata={\"team\":\"1\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0ngArVmUpub",
        "outputId": "e6759c63-51f8-4389-b20e-c9135254c3c3"
      },
      "id": "j0ngArVmUpub",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 836\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5"
      ],
      "metadata": {
        "id": "FnunOP9YWU29"
      },
      "id": "FnunOP9YWU29"
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = GradientBoostingClassifier(n_estimators=9, learning_rate=1.0,\n",
        "    max_depth=1, random_state=0).fit(preprocessor(X_train), y_train_labels)\n",
        "model_5.score(preprocessor(X_train), y_train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA0s3Au4WXGJ",
        "outputId": "253259c6-3714-40dc-99e0-e0d8c3f87fc9"
      },
      "id": "gA0s3Au4WXGJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9659090909090909"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Generate predicted values \n",
        "prediction_labels = model_5.predict(preprocessor(X_test))"
      ],
      "metadata": {
        "id": "Fddr-XncXBkZ"
      },
      "id": "Fddr-XncXBkZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit model to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels, custom_metadata={\"team\":\"1\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEGujwN6W8xX",
        "outputId": "6faff4b6-d2ea-4558-fbfb-d1bc838694ae"
      },
      "id": "rEGujwN6W8xX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 827\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 6"
      ],
      "metadata": {
        "id": "FrKXYNrHXb8M"
      },
      "id": "FrKXYNrHXb8M"
    },
    {
      "cell_type": "code",
      "source": [
        "feature_count=preprocessor(X_train).shape[1] #count features in input data\n",
        "\n",
        "keras_model = Sequential()\n",
        "keras_model.add(Dense(128, input_dim=feature_count, activation='relu'))\n",
        "keras_model.add(Dense(64, activation='relu'))\n",
        "keras_model.add(Dense(64, activation='relu'))\n",
        "keras_model.add(Dense(64, activation='relu'))\n",
        "\n",
        "keras_model.add(Dense(5, activation='softmax')) \n",
        "                                            \n",
        "# Compile model\n",
        "keras_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# Fitting the NN to the Training set\n",
        "keras_model.fit(preprocessor(X_train), y_train, ## Note that keras models require a one-hot-encoded y_train object\n",
        "               batch_size = 20, \n",
        "               epochs = 300, validation_split=0.25)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH_9ihbsXbXd",
        "outputId": "9aa4831f-53a7-4083-c1f9-72a2f9782fc7"
      },
      "id": "XH_9ihbsXbXd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 67ms/step - loss: 1.6024 - accuracy: 0.1818 - val_loss: 1.6003 - val_accuracy: 0.2727\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5910 - accuracy: 0.1970 - val_loss: 1.5949 - val_accuracy: 0.2727\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5808 - accuracy: 0.2576 - val_loss: 1.5909 - val_accuracy: 0.1364\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.5703 - accuracy: 0.2576 - val_loss: 1.5871 - val_accuracy: 0.2273\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5615 - accuracy: 0.3333 - val_loss: 1.5834 - val_accuracy: 0.2273\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.5529 - accuracy: 0.3636 - val_loss: 1.5792 - val_accuracy: 0.1364\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5430 - accuracy: 0.3788 - val_loss: 1.5745 - val_accuracy: 0.1364\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.5341 - accuracy: 0.3939 - val_loss: 1.5715 - val_accuracy: 0.1818\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.5247 - accuracy: 0.3939 - val_loss: 1.5674 - val_accuracy: 0.2727\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5164 - accuracy: 0.4394 - val_loss: 1.5635 - val_accuracy: 0.2727\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.5089 - accuracy: 0.4848 - val_loss: 1.5596 - val_accuracy: 0.3182\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5003 - accuracy: 0.5455 - val_loss: 1.5553 - val_accuracy: 0.3182\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.4919 - accuracy: 0.5606 - val_loss: 1.5509 - val_accuracy: 0.2727\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4837 - accuracy: 0.5758 - val_loss: 1.5464 - val_accuracy: 0.3182\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4748 - accuracy: 0.5758 - val_loss: 1.5419 - val_accuracy: 0.3182\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4665 - accuracy: 0.5758 - val_loss: 1.5356 - val_accuracy: 0.3182\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4574 - accuracy: 0.5758 - val_loss: 1.5327 - val_accuracy: 0.3636\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4492 - accuracy: 0.5909 - val_loss: 1.5274 - val_accuracy: 0.3636\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4403 - accuracy: 0.6061 - val_loss: 1.5198 - val_accuracy: 0.3636\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.4303 - accuracy: 0.6212 - val_loss: 1.5153 - val_accuracy: 0.3636\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.4226 - accuracy: 0.6364 - val_loss: 1.5100 - val_accuracy: 0.3182\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4129 - accuracy: 0.6364 - val_loss: 1.5018 - val_accuracy: 0.3636\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.4026 - accuracy: 0.6212 - val_loss: 1.4969 - val_accuracy: 0.3636\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3926 - accuracy: 0.6212 - val_loss: 1.4913 - val_accuracy: 0.3636\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3821 - accuracy: 0.6212 - val_loss: 1.4870 - val_accuracy: 0.3182\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3714 - accuracy: 0.6212 - val_loss: 1.4804 - val_accuracy: 0.3182\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3617 - accuracy: 0.6212 - val_loss: 1.4733 - val_accuracy: 0.3182\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.3525 - accuracy: 0.6212 - val_loss: 1.4664 - val_accuracy: 0.4091\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3420 - accuracy: 0.6212 - val_loss: 1.4597 - val_accuracy: 0.3636\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3306 - accuracy: 0.6212 - val_loss: 1.4498 - val_accuracy: 0.4091\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.3204 - accuracy: 0.6212 - val_loss: 1.4423 - val_accuracy: 0.3636\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3096 - accuracy: 0.6212 - val_loss: 1.4336 - val_accuracy: 0.4091\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2993 - accuracy: 0.6212 - val_loss: 1.4224 - val_accuracy: 0.4091\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.2880 - accuracy: 0.6212 - val_loss: 1.4143 - val_accuracy: 0.4091\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.2773 - accuracy: 0.6364 - val_loss: 1.4062 - val_accuracy: 0.4091\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2666 - accuracy: 0.6364 - val_loss: 1.4006 - val_accuracy: 0.4091\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.2551 - accuracy: 0.6061 - val_loss: 1.3890 - val_accuracy: 0.4091\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2426 - accuracy: 0.6212 - val_loss: 1.3831 - val_accuracy: 0.4091\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.2314 - accuracy: 0.5909 - val_loss: 1.3760 - val_accuracy: 0.4091\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2193 - accuracy: 0.6212 - val_loss: 1.3682 - val_accuracy: 0.4091\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2089 - accuracy: 0.6364 - val_loss: 1.3610 - val_accuracy: 0.4091\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.1977 - accuracy: 0.6212 - val_loss: 1.3554 - val_accuracy: 0.4091\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1864 - accuracy: 0.6364 - val_loss: 1.3461 - val_accuracy: 0.4091\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1765 - accuracy: 0.6364 - val_loss: 1.3410 - val_accuracy: 0.4091\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1648 - accuracy: 0.6364 - val_loss: 1.3321 - val_accuracy: 0.4091\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1534 - accuracy: 0.6212 - val_loss: 1.3238 - val_accuracy: 0.4091\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1418 - accuracy: 0.6364 - val_loss: 1.3142 - val_accuracy: 0.4091\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.1299 - accuracy: 0.6364 - val_loss: 1.3009 - val_accuracy: 0.4545\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1182 - accuracy: 0.6364 - val_loss: 1.2932 - val_accuracy: 0.4545\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1074 - accuracy: 0.6364 - val_loss: 1.2862 - val_accuracy: 0.4545\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0965 - accuracy: 0.6515 - val_loss: 1.2757 - val_accuracy: 0.4545\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0854 - accuracy: 0.6364 - val_loss: 1.2675 - val_accuracy: 0.4545\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.0743 - accuracy: 0.6515 - val_loss: 1.2646 - val_accuracy: 0.4545\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0631 - accuracy: 0.6515 - val_loss: 1.2595 - val_accuracy: 0.4545\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0529 - accuracy: 0.6364 - val_loss: 1.2521 - val_accuracy: 0.4545\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0413 - accuracy: 0.6364 - val_loss: 1.2442 - val_accuracy: 0.4545\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.0313 - accuracy: 0.6515 - val_loss: 1.2350 - val_accuracy: 0.4545\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0206 - accuracy: 0.6515 - val_loss: 1.2282 - val_accuracy: 0.4545\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.0090 - accuracy: 0.6515 - val_loss: 1.2254 - val_accuracy: 0.4545\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9994 - accuracy: 0.6364 - val_loss: 1.2164 - val_accuracy: 0.4545\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9905 - accuracy: 0.6364 - val_loss: 1.2110 - val_accuracy: 0.4545\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9800 - accuracy: 0.6515 - val_loss: 1.2061 - val_accuracy: 0.4545\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9698 - accuracy: 0.6667 - val_loss: 1.2072 - val_accuracy: 0.4545\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9607 - accuracy: 0.6515 - val_loss: 1.2003 - val_accuracy: 0.4545\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9523 - accuracy: 0.6515 - val_loss: 1.1913 - val_accuracy: 0.4545\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9412 - accuracy: 0.6515 - val_loss: 1.1886 - val_accuracy: 0.4545\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9325 - accuracy: 0.6515 - val_loss: 1.1814 - val_accuracy: 0.4545\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.9251 - accuracy: 0.6364 - val_loss: 1.1686 - val_accuracy: 0.4545\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9150 - accuracy: 0.6364 - val_loss: 1.1590 - val_accuracy: 0.4545\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9079 - accuracy: 0.6667 - val_loss: 1.1490 - val_accuracy: 0.4545\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8984 - accuracy: 0.6818 - val_loss: 1.1347 - val_accuracy: 0.4545\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.8912 - accuracy: 0.6667 - val_loss: 1.1334 - val_accuracy: 0.4545\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8812 - accuracy: 0.6818 - val_loss: 1.1250 - val_accuracy: 0.4545\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8734 - accuracy: 0.6818 - val_loss: 1.1237 - val_accuracy: 0.4545\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8661 - accuracy: 0.6970 - val_loss: 1.1190 - val_accuracy: 0.4545\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8577 - accuracy: 0.6970 - val_loss: 1.1170 - val_accuracy: 0.4545\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8488 - accuracy: 0.6970 - val_loss: 1.1049 - val_accuracy: 0.4545\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8413 - accuracy: 0.6970 - val_loss: 1.0998 - val_accuracy: 0.4545\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8347 - accuracy: 0.6970 - val_loss: 1.1020 - val_accuracy: 0.4545\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8267 - accuracy: 0.6970 - val_loss: 1.0926 - val_accuracy: 0.4545\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8195 - accuracy: 0.7121 - val_loss: 1.0785 - val_accuracy: 0.5000\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8113 - accuracy: 0.7121 - val_loss: 1.0776 - val_accuracy: 0.4545\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8049 - accuracy: 0.7273 - val_loss: 1.0655 - val_accuracy: 0.5000\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7974 - accuracy: 0.7273 - val_loss: 1.0488 - val_accuracy: 0.5000\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7921 - accuracy: 0.7273 - val_loss: 1.0450 - val_accuracy: 0.5455\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7870 - accuracy: 0.7424 - val_loss: 1.0397 - val_accuracy: 0.5000\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7806 - accuracy: 0.7273 - val_loss: 1.0392 - val_accuracy: 0.5455\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7718 - accuracy: 0.7273 - val_loss: 1.0401 - val_accuracy: 0.5000\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7669 - accuracy: 0.7576 - val_loss: 1.0342 - val_accuracy: 0.5455\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7579 - accuracy: 0.7576 - val_loss: 1.0316 - val_accuracy: 0.5000\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7506 - accuracy: 0.7576 - val_loss: 1.0357 - val_accuracy: 0.5455\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7447 - accuracy: 0.7576 - val_loss: 1.0359 - val_accuracy: 0.5455\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7381 - accuracy: 0.7576 - val_loss: 1.0282 - val_accuracy: 0.4545\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7336 - accuracy: 0.7727 - val_loss: 1.0259 - val_accuracy: 0.4545\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7277 - accuracy: 0.7576 - val_loss: 1.0261 - val_accuracy: 0.5455\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7200 - accuracy: 0.7727 - val_loss: 1.0227 - val_accuracy: 0.5000\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7156 - accuracy: 0.7727 - val_loss: 1.0342 - val_accuracy: 0.5000\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7110 - accuracy: 0.7727 - val_loss: 1.0417 - val_accuracy: 0.5000\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7037 - accuracy: 0.7727 - val_loss: 1.0287 - val_accuracy: 0.4545\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6988 - accuracy: 0.7727 - val_loss: 1.0088 - val_accuracy: 0.5000\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.7727 - val_loss: 1.0221 - val_accuracy: 0.5000\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6895 - accuracy: 0.7727 - val_loss: 0.9933 - val_accuracy: 0.5000\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6832 - accuracy: 0.7576 - val_loss: 0.9929 - val_accuracy: 0.5000\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6775 - accuracy: 0.7576 - val_loss: 0.9882 - val_accuracy: 0.5000\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6696 - accuracy: 0.7879 - val_loss: 0.9890 - val_accuracy: 0.5000\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.6675 - accuracy: 0.7727 - val_loss: 0.9846 - val_accuracy: 0.5455\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.6599 - accuracy: 0.7879 - val_loss: 0.9901 - val_accuracy: 0.5455\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6537 - accuracy: 0.8030 - val_loss: 0.9893 - val_accuracy: 0.5455\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6506 - accuracy: 0.7879 - val_loss: 0.9698 - val_accuracy: 0.5455\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6430 - accuracy: 0.8030 - val_loss: 0.9652 - val_accuracy: 0.5455\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6387 - accuracy: 0.8030 - val_loss: 0.9690 - val_accuracy: 0.5455\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6331 - accuracy: 0.8182 - val_loss: 0.9597 - val_accuracy: 0.5455\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6272 - accuracy: 0.8182 - val_loss: 0.9726 - val_accuracy: 0.5455\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6240 - accuracy: 0.8182 - val_loss: 0.9694 - val_accuracy: 0.5455\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6228 - accuracy: 0.8030 - val_loss: 0.9759 - val_accuracy: 0.5455\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6152 - accuracy: 0.8182 - val_loss: 0.9881 - val_accuracy: 0.5455\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.6129 - accuracy: 0.8030 - val_loss: 0.9824 - val_accuracy: 0.5455\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6043 - accuracy: 0.8182 - val_loss: 0.9752 - val_accuracy: 0.5455\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6008 - accuracy: 0.8182 - val_loss: 0.9569 - val_accuracy: 0.5455\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5943 - accuracy: 0.8182 - val_loss: 0.9427 - val_accuracy: 0.5000\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5910 - accuracy: 0.8182 - val_loss: 0.9446 - val_accuracy: 0.5000\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5865 - accuracy: 0.8182 - val_loss: 0.9394 - val_accuracy: 0.5455\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5851 - accuracy: 0.8485 - val_loss: 0.9663 - val_accuracy: 0.5000\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.5794 - accuracy: 0.8182 - val_loss: 0.9693 - val_accuracy: 0.5455\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5757 - accuracy: 0.8182 - val_loss: 0.9678 - val_accuracy: 0.5000\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5736 - accuracy: 0.8182 - val_loss: 0.9720 - val_accuracy: 0.5909\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5649 - accuracy: 0.8182 - val_loss: 0.9691 - val_accuracy: 0.5455\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5586 - accuracy: 0.8333 - val_loss: 0.9503 - val_accuracy: 0.5455\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5527 - accuracy: 0.8485 - val_loss: 0.9584 - val_accuracy: 0.5455\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5501 - accuracy: 0.8485 - val_loss: 0.9516 - val_accuracy: 0.5000\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5474 - accuracy: 0.8485 - val_loss: 0.9682 - val_accuracy: 0.5455\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5440 - accuracy: 0.8485 - val_loss: 0.9553 - val_accuracy: 0.5455\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5408 - accuracy: 0.8788 - val_loss: 0.9533 - val_accuracy: 0.5455\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5353 - accuracy: 0.8485 - val_loss: 0.9508 - val_accuracy: 0.5455\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.8788 - val_loss: 0.9119 - val_accuracy: 0.5909\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5296 - accuracy: 0.8182 - val_loss: 0.8962 - val_accuracy: 0.6364\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5292 - accuracy: 0.8182 - val_loss: 0.8911 - val_accuracy: 0.6364\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5203 - accuracy: 0.8333 - val_loss: 0.9177 - val_accuracy: 0.6364\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5185 - accuracy: 0.8485 - val_loss: 0.9131 - val_accuracy: 0.6364\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5104 - accuracy: 0.8485 - val_loss: 0.9116 - val_accuracy: 0.5909\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5083 - accuracy: 0.8182 - val_loss: 0.9169 - val_accuracy: 0.5909\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4998 - accuracy: 0.8333 - val_loss: 0.9280 - val_accuracy: 0.5909\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5010 - accuracy: 0.8182 - val_loss: 0.9323 - val_accuracy: 0.5455\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4943 - accuracy: 0.8485 - val_loss: 0.9358 - val_accuracy: 0.5455\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4913 - accuracy: 0.8485 - val_loss: 0.9308 - val_accuracy: 0.5455\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4854 - accuracy: 0.8636 - val_loss: 0.9106 - val_accuracy: 0.5909\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4827 - accuracy: 0.8333 - val_loss: 0.9188 - val_accuracy: 0.5455\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4821 - accuracy: 0.8182 - val_loss: 0.9178 - val_accuracy: 0.5909\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4783 - accuracy: 0.8182 - val_loss: 0.9270 - val_accuracy: 0.5455\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4727 - accuracy: 0.8333 - val_loss: 0.9506 - val_accuracy: 0.5000\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4704 - accuracy: 0.8636 - val_loss: 0.9306 - val_accuracy: 0.5455\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4660 - accuracy: 0.8485 - val_loss: 0.9301 - val_accuracy: 0.5909\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4654 - accuracy: 0.8333 - val_loss: 0.9321 - val_accuracy: 0.5909\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4586 - accuracy: 0.8485 - val_loss: 0.9566 - val_accuracy: 0.5455\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4583 - accuracy: 0.8636 - val_loss: 0.9483 - val_accuracy: 0.5455\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4539 - accuracy: 0.8636 - val_loss: 0.9331 - val_accuracy: 0.5909\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4498 - accuracy: 0.8636 - val_loss: 0.9611 - val_accuracy: 0.5455\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4496 - accuracy: 0.8485 - val_loss: 0.9448 - val_accuracy: 0.5455\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4473 - accuracy: 0.8485 - val_loss: 0.9391 - val_accuracy: 0.5909\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4403 - accuracy: 0.8636 - val_loss: 0.9296 - val_accuracy: 0.6364\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4385 - accuracy: 0.8788 - val_loss: 0.9409 - val_accuracy: 0.6364\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4315 - accuracy: 0.8939 - val_loss: 0.9326 - val_accuracy: 0.5455\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4360 - accuracy: 0.8485 - val_loss: 0.9398 - val_accuracy: 0.5455\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4301 - accuracy: 0.8636 - val_loss: 0.9495 - val_accuracy: 0.5909\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4253 - accuracy: 0.8788 - val_loss: 0.9372 - val_accuracy: 0.5455\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4181 - accuracy: 0.8788 - val_loss: 0.9311 - val_accuracy: 0.6364\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4183 - accuracy: 0.8788 - val_loss: 0.9392 - val_accuracy: 0.5909\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4125 - accuracy: 0.8788 - val_loss: 0.9471 - val_accuracy: 0.5455\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4142 - accuracy: 0.8485 - val_loss: 0.9451 - val_accuracy: 0.6364\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4086 - accuracy: 0.8939 - val_loss: 0.9445 - val_accuracy: 0.6364\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4046 - accuracy: 0.9091 - val_loss: 0.9370 - val_accuracy: 0.6364\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4026 - accuracy: 0.8788 - val_loss: 0.9273 - val_accuracy: 0.6364\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4035 - accuracy: 0.8636 - val_loss: 0.9479 - val_accuracy: 0.6364\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3940 - accuracy: 0.9091 - val_loss: 0.9505 - val_accuracy: 0.5909\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3917 - accuracy: 0.9091 - val_loss: 0.9674 - val_accuracy: 0.5909\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3907 - accuracy: 0.8939 - val_loss: 0.9802 - val_accuracy: 0.6364\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3857 - accuracy: 0.9091 - val_loss: 0.9511 - val_accuracy: 0.6364\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3847 - accuracy: 0.8939 - val_loss: 0.9389 - val_accuracy: 0.5909\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3815 - accuracy: 0.8939 - val_loss: 0.9467 - val_accuracy: 0.6364\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3784 - accuracy: 0.8939 - val_loss: 0.9667 - val_accuracy: 0.5909\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3748 - accuracy: 0.8939 - val_loss: 0.9677 - val_accuracy: 0.5909\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3754 - accuracy: 0.8939 - val_loss: 0.9398 - val_accuracy: 0.6364\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3727 - accuracy: 0.8788 - val_loss: 0.9448 - val_accuracy: 0.6364\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3679 - accuracy: 0.8788 - val_loss: 0.9543 - val_accuracy: 0.5909\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3635 - accuracy: 0.8939 - val_loss: 0.9614 - val_accuracy: 0.5909\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3608 - accuracy: 0.9091 - val_loss: 0.9435 - val_accuracy: 0.5909\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3600 - accuracy: 0.8939 - val_loss: 0.9411 - val_accuracy: 0.5909\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3583 - accuracy: 0.8788 - val_loss: 0.9540 - val_accuracy: 0.6364\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3508 - accuracy: 0.9091 - val_loss: 0.9300 - val_accuracy: 0.6364\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3541 - accuracy: 0.8788 - val_loss: 0.9592 - val_accuracy: 0.6364\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3490 - accuracy: 0.9091 - val_loss: 0.9642 - val_accuracy: 0.6364\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3469 - accuracy: 0.8939 - val_loss: 0.9982 - val_accuracy: 0.6364\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3451 - accuracy: 0.9242 - val_loss: 0.9936 - val_accuracy: 0.6364\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3443 - accuracy: 0.9242 - val_loss: 1.0240 - val_accuracy: 0.6364\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3427 - accuracy: 0.9091 - val_loss: 1.0259 - val_accuracy: 0.6364\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3389 - accuracy: 0.9242 - val_loss: 0.9960 - val_accuracy: 0.5909\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3363 - accuracy: 0.9242 - val_loss: 1.0014 - val_accuracy: 0.5909\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3308 - accuracy: 0.9242 - val_loss: 1.0077 - val_accuracy: 0.5909\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3296 - accuracy: 0.9242 - val_loss: 0.9826 - val_accuracy: 0.6364\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3275 - accuracy: 0.9242 - val_loss: 1.0211 - val_accuracy: 0.6364\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3240 - accuracy: 0.9242 - val_loss: 1.0138 - val_accuracy: 0.6364\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3259 - accuracy: 0.9242 - val_loss: 0.9943 - val_accuracy: 0.6364\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3171 - accuracy: 0.9242 - val_loss: 0.9889 - val_accuracy: 0.6364\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3218 - accuracy: 0.9091 - val_loss: 0.9373 - val_accuracy: 0.6364\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3210 - accuracy: 0.8788 - val_loss: 0.9524 - val_accuracy: 0.5909\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3145 - accuracy: 0.8788 - val_loss: 0.9787 - val_accuracy: 0.6364\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3131 - accuracy: 0.9242 - val_loss: 0.9502 - val_accuracy: 0.6364\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3218 - accuracy: 0.8788 - val_loss: 0.9685 - val_accuracy: 0.6818\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3127 - accuracy: 0.8788 - val_loss: 0.9945 - val_accuracy: 0.5909\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3032 - accuracy: 0.9091 - val_loss: 1.0374 - val_accuracy: 0.5909\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3046 - accuracy: 0.9242 - val_loss: 1.0109 - val_accuracy: 0.6364\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3015 - accuracy: 0.8939 - val_loss: 1.0194 - val_accuracy: 0.6364\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3036 - accuracy: 0.9091 - val_loss: 1.0114 - val_accuracy: 0.5455\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2965 - accuracy: 0.9242 - val_loss: 0.9399 - val_accuracy: 0.6818\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2972 - accuracy: 0.8788 - val_loss: 0.9774 - val_accuracy: 0.6364\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2904 - accuracy: 0.9091 - val_loss: 1.0016 - val_accuracy: 0.6364\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2871 - accuracy: 0.9091 - val_loss: 1.0106 - val_accuracy: 0.6364\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2879 - accuracy: 0.9242 - val_loss: 1.0091 - val_accuracy: 0.6364\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2839 - accuracy: 0.9091 - val_loss: 1.0163 - val_accuracy: 0.6364\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2801 - accuracy: 0.9242 - val_loss: 1.0441 - val_accuracy: 0.6364\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2792 - accuracy: 0.9242 - val_loss: 1.0326 - val_accuracy: 0.6364\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2773 - accuracy: 0.9091 - val_loss: 1.0590 - val_accuracy: 0.5909\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2781 - accuracy: 0.9394 - val_loss: 1.0803 - val_accuracy: 0.5909\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2785 - accuracy: 0.9242 - val_loss: 1.0557 - val_accuracy: 0.5909\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2722 - accuracy: 0.9242 - val_loss: 1.0460 - val_accuracy: 0.6364\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2682 - accuracy: 0.9242 - val_loss: 1.0401 - val_accuracy: 0.6364\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2694 - accuracy: 0.9242 - val_loss: 1.0549 - val_accuracy: 0.5909\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2650 - accuracy: 0.9242 - val_loss: 0.9889 - val_accuracy: 0.6364\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.8939 - val_loss: 0.9720 - val_accuracy: 0.6364\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2721 - accuracy: 0.8939 - val_loss: 1.0146 - val_accuracy: 0.6364\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2636 - accuracy: 0.9091 - val_loss: 1.0230 - val_accuracy: 0.5909\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2634 - accuracy: 0.9394 - val_loss: 0.9698 - val_accuracy: 0.6818\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2656 - accuracy: 0.9242 - val_loss: 1.0116 - val_accuracy: 0.5909\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2583 - accuracy: 0.9242 - val_loss: 0.9995 - val_accuracy: 0.6818\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2670 - accuracy: 0.9091 - val_loss: 1.0269 - val_accuracy: 0.6818\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2525 - accuracy: 0.9091 - val_loss: 1.0842 - val_accuracy: 0.6364\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2489 - accuracy: 0.9242 - val_loss: 1.0899 - val_accuracy: 0.6364\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2490 - accuracy: 0.9394 - val_loss: 1.0683 - val_accuracy: 0.6364\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2457 - accuracy: 0.9545 - val_loss: 1.0886 - val_accuracy: 0.6364\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2428 - accuracy: 0.9242 - val_loss: 1.0749 - val_accuracy: 0.6364\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2397 - accuracy: 0.9242 - val_loss: 1.0702 - val_accuracy: 0.6364\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2442 - accuracy: 0.9545 - val_loss: 1.0644 - val_accuracy: 0.6364\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2396 - accuracy: 0.9394 - val_loss: 1.0945 - val_accuracy: 0.5909\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2385 - accuracy: 0.9545 - val_loss: 1.0931 - val_accuracy: 0.5909\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2363 - accuracy: 0.9394 - val_loss: 1.0881 - val_accuracy: 0.6364\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2333 - accuracy: 0.9091 - val_loss: 1.0840 - val_accuracy: 0.5455\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2324 - accuracy: 0.9091 - val_loss: 1.1218 - val_accuracy: 0.5909\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2353 - accuracy: 0.9545 - val_loss: 1.0944 - val_accuracy: 0.5455\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2296 - accuracy: 0.9545 - val_loss: 1.1189 - val_accuracy: 0.5909\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2261 - accuracy: 0.9545 - val_loss: 1.0957 - val_accuracy: 0.5455\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2290 - accuracy: 0.9545 - val_loss: 1.0228 - val_accuracy: 0.5909\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2355 - accuracy: 0.9394 - val_loss: 1.0998 - val_accuracy: 0.5909\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2237 - accuracy: 0.9394 - val_loss: 1.1093 - val_accuracy: 0.5909\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2203 - accuracy: 0.9545 - val_loss: 1.0965 - val_accuracy: 0.5909\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2219 - accuracy: 0.9545 - val_loss: 1.0909 - val_accuracy: 0.5455\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2234 - accuracy: 0.9242 - val_loss: 1.0987 - val_accuracy: 0.5909\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2165 - accuracy: 0.9545 - val_loss: 1.1154 - val_accuracy: 0.5909\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2149 - accuracy: 0.9394 - val_loss: 1.1153 - val_accuracy: 0.5909\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2148 - accuracy: 0.9545 - val_loss: 1.1252 - val_accuracy: 0.5909\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2121 - accuracy: 0.9545 - val_loss: 1.1135 - val_accuracy: 0.5909\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2104 - accuracy: 0.9545 - val_loss: 1.1262 - val_accuracy: 0.5455\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2120 - accuracy: 0.9394 - val_loss: 1.1384 - val_accuracy: 0.5455\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2062 - accuracy: 0.9545 - val_loss: 1.1545 - val_accuracy: 0.5455\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2130 - accuracy: 0.9545 - val_loss: 1.0673 - val_accuracy: 0.5909\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2141 - accuracy: 0.9545 - val_loss: 1.1421 - val_accuracy: 0.5455\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2054 - accuracy: 0.9545 - val_loss: 1.1374 - val_accuracy: 0.5909\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 0.9545 - val_loss: 1.1486 - val_accuracy: 0.5455\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2035 - accuracy: 0.9394 - val_loss: 1.2121 - val_accuracy: 0.5455\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2026 - accuracy: 0.9545 - val_loss: 1.1750 - val_accuracy: 0.5909\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2021 - accuracy: 0.9545 - val_loss: 1.2011 - val_accuracy: 0.5909\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2030 - accuracy: 0.9545 - val_loss: 1.1704 - val_accuracy: 0.5909\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1997 - accuracy: 0.9545 - val_loss: 1.0924 - val_accuracy: 0.6364\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2021 - accuracy: 0.9545 - val_loss: 1.2176 - val_accuracy: 0.5909\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1972 - accuracy: 0.9545 - val_loss: 1.2005 - val_accuracy: 0.5909\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1956 - accuracy: 0.9545 - val_loss: 1.1746 - val_accuracy: 0.5909\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1879 - accuracy: 0.9545 - val_loss: 1.1667 - val_accuracy: 0.5455\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1901 - accuracy: 0.9545 - val_loss: 1.1809 - val_accuracy: 0.5909\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1895 - accuracy: 0.9545 - val_loss: 1.2052 - val_accuracy: 0.5455\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1916 - accuracy: 0.9394 - val_loss: 1.2259 - val_accuracy: 0.5909\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1857 - accuracy: 0.9545 - val_loss: 1.2031 - val_accuracy: 0.5455\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1834 - accuracy: 0.9545 - val_loss: 1.1872 - val_accuracy: 0.5909\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1884 - accuracy: 0.9545 - val_loss: 1.2034 - val_accuracy: 0.5909\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1836 - accuracy: 0.9697 - val_loss: 1.2026 - val_accuracy: 0.5909\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1844 - accuracy: 0.9697 - val_loss: 1.1118 - val_accuracy: 0.6364\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1917 - accuracy: 0.9545 - val_loss: 1.1750 - val_accuracy: 0.5909\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1772 - accuracy: 0.9545 - val_loss: 1.2117 - val_accuracy: 0.5909\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1807 - accuracy: 0.9394 - val_loss: 1.2588 - val_accuracy: 0.5909\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1822 - accuracy: 0.9545 - val_loss: 1.2505 - val_accuracy: 0.5909\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1757 - accuracy: 0.9545 - val_loss: 1.2337 - val_accuracy: 0.5455\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1793 - accuracy: 0.9545 - val_loss: 1.2121 - val_accuracy: 0.5455\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1732 - accuracy: 0.9545 - val_loss: 1.2253 - val_accuracy: 0.5909\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1707 - accuracy: 0.9545 - val_loss: 1.2062 - val_accuracy: 0.5909\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1709 - accuracy: 0.9545 - val_loss: 1.2484 - val_accuracy: 0.5455\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1774 - accuracy: 0.9545 - val_loss: 1.2178 - val_accuracy: 0.5455\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1682 - accuracy: 0.9545 - val_loss: 1.2224 - val_accuracy: 0.5455\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1744 - accuracy: 0.9242 - val_loss: 1.2684 - val_accuracy: 0.5455\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1669 - accuracy: 0.9545 - val_loss: 1.2434 - val_accuracy: 0.5455\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1723 - accuracy: 0.9394 - val_loss: 1.2655 - val_accuracy: 0.5455\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1685 - accuracy: 0.9394 - val_loss: 1.2573 - val_accuracy: 0.5455\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1671 - accuracy: 0.9545 - val_loss: 1.1620 - val_accuracy: 0.5909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e0c24dc70>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to ONNX file \n",
        "\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(keras_model, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "HoAqfpOaYXdR"
      },
      "id": "HoAqfpOaYXdR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit keras model: \n",
        "\n",
        "#-- Generate predicted y values\n",
        "#Note: Keras predict returns the predicted column index location for classification models\n",
        "prediction_column_index=keras_model.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels, custom_metadata={\"team\":\"1\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d4oTEvbYYx7",
        "outputId": "bbc90a69-6dd4-4676-e649-c4a68b3330e6"
      },
      "id": "-d4oTEvbYYx7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 832\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Classifier Model perform the best, the relevant hyper parameters are max_depth=1 and n_estimators=100"
      ],
      "metadata": {
        "id": "T_tpah45Y4Ky"
      },
      "id": "T_tpah45Y4Ky"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to GitHub Repo: https://github.com/Estelleccc/ml-project-steps/tree/main/Homework"
      ],
      "metadata": {
        "id": "uF-MYoiwh2_T"
      },
      "id": "uF-MYoiwh2_T"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
